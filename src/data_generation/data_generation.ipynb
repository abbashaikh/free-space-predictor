{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a1282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbas/miniconda3/envs/fsp/lib/python3.9/site-packages/wandb/sdk/internal/internal_api.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from typing import Dict, List\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from trajdata import UnifiedDataset, SceneBatch, AgentBatch\n",
    "from trajdata.data_structures.agent import AgentType\n",
    "from trajdata.augmentation import NoiseHistories\n",
    "\n",
    "from data_generation import (\n",
    "    # custom batch\n",
    "    SceneAgentBatch,\n",
    "    SceneProcessor,\n",
    "    # custom data\n",
    "    custom_world_from_agent_tf,\n",
    "    get_neigh_idxs,\n",
    "    custom_agent_neigh_hist,\n",
    "    custom_agent_fut,\n",
    "    custom_collate_fn,\n",
    "    transform_coords_np,\n",
    "    # utils\n",
    "    load_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d65751",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '../../data/trained_models/trajectory_prediction'\n",
    "model_dir = os.path.join(log_dir, \"eth_loo-29_May_2025_22_55_51\")\n",
    "\n",
    "with open(os.path.join(model_dir, 'config.json'), 'r', encoding=\"utf-8\") as config_json:\n",
    "    hyperparams = json.load(config_json)\n",
    "# device\n",
    "hyperparams[\"device\"] = \"cpu\"\n",
    "hyperparams[\"trajdata_cache_dir\"] = \"../../data/pedestrian_datasets/.unified_data_cache\"\n",
    "\n",
    "desired_data=[\n",
    "    \"eupeds_eth-train\",\n",
    "]\n",
    "max_agent_num = 20\n",
    "data_dirs = {\n",
    "    \"eupeds_eth\": \"../../data/pedestrian_datasets/eth_ucy_peds\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71995f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['train_loo-eupeds_eth']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Scenes from eupeds_eth: 100%|██████████| 1/1 [00:00<00:00, 2748.56it/s]\n",
      "Calculating Agent Data (Serially): 100%|██████████| 7/7 [00:00<00:00, 17538.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Scene Data Index (16 CPUs): 100%|██████████| 7/7 [00:00<00:00, 1106.22it/s]\n",
      "Structuring Scene Data Index: 100%|██████████| 7/7 [00:00<00:00, 264505.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Data Samples: 4356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "# attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 5.0\n",
    "interaction_radius = 5.0\n",
    "\n",
    "history_sec = (0.1, hyperparams[\"history_sec\"])\n",
    "future_sec = (0.1, hyperparams[\"prediction_sec\"])\n",
    "\n",
    "input_noise = 0.0\n",
    "augmentations = list()\n",
    "if input_noise > 0.0:\n",
    "    augmentations.append(NoiseHistories(stddev=input_noise))\n",
    "\n",
    "num_scenes = 1\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=desired_data,\n",
    "    centric=\"scene\",\n",
    "    # centric=\"agent\",\n",
    "    history_sec=history_sec,\n",
    "    future_sec=future_sec,\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    max_agent_num=max_agent_num,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    augmentations=augmentations if len(augmentations) > 0 else None,\n",
    "    standardize_data=False,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    data_dirs=data_dirs,\n",
    "    verbose=True,\n",
    "    extras={\n",
    "        \"world_from_agent_tf\": custom_world_from_agent_tf,\n",
    "        \"is_neigh\": partial(get_neigh_idxs, interaction_radius=interaction_radius),\n",
    "        \"agent_neigh_hist_st\": partial(custom_agent_neigh_hist, history_sec=history_sec),\n",
    "        \"agent_fut_st\": partial(custom_agent_fut, future_sec=future_sec),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"# Data Samples: {len(dataset)}\")\n",
    "\n",
    "base_collate = dataset.get_collate_fn(pad_format=\"right\")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    # collate_fn=dataset.get_collate_fn(pad_format=\"right\"),\n",
    "    collate_fn=partial(\n",
    "        custom_collate_fn,\n",
    "        history_sec=history_sec,\n",
    "        future_sec=future_sec,\n",
    "        base_collate=base_collate\n",
    "        ),\n",
    "    pin_memory=False if hyperparams[\"device\"] == \"cpu\" else True,\n",
    "    batch_size=num_scenes,\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    sampler=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c446eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch: AgentBatch = next(iter(dataloader))\n",
    "batch: SceneBatch = next(iter(dataloader))\n",
    "scene_batch = SceneAgentBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_processor = SceneProcessor(scene_batch) # ensure only one scene is passed\n",
    "\n",
    "epoch = 15\n",
    "predictor = load_model(model_dir=model_dir, epoch=epoch, hyperparams=hyperparams)\n",
    "ego_positions = scene_processor.get_ego_positions(samples_per_scene=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e676073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, 3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supports = scene_processor.scene_supports(ego_positions, risk=0.05, confidence=0.01)\n",
    "supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ego position and support data\n",
    "for batch in dataloader:\n",
    "    scene_batch = SceneAgentBatch(batch)\n",
    "    ego_positions = scene_processor.get_ego_positions(samples_per_scene=5)\n",
    "    supports = scene_processor.scene_supports(ego_positions, risk=0.05, confidence=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019cbd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ccbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59adf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## initiate plot\n",
    "xLim = 15\n",
    "yLim = 15\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(-xLim, xLim)\n",
    "ax.set_ylim(-yLim, yLim)\n",
    "\n",
    "ts = 0\n",
    "\n",
    "for idx, human_pos in enumerate(flat_preds[ts]):\n",
    "     # Create a circle for each agent\n",
    "    color = (random.random(), random.random(), random.random()) # Generate a random color for each agent\n",
    "\n",
    "    # Draw the agent's current position\n",
    "    circle = plt.Circle(\n",
    "        (human_pos[0], human_pos[1]),\n",
    "        0.5,\n",
    "        facecolor=color,\n",
    "        edgecolor=\"k\",\n",
    "        lw=0.5,\n",
    "        zorder=3,\n",
    "    )\n",
    "    ax.add_artist(circle)\n",
    "    # ax.annotate(\n",
    "    #     obs.agent_name[idx],\n",
    "    #     (human_pos[0], human_pos[1]),\n",
    "    #     fontsize=8,\n",
    "    #     ha=\"center\",\n",
    "    #     va=\"center\",\n",
    "    # )\n",
    "\n",
    "    # Plot future positions with decreasing transparency\n",
    "    # alpha = 1.0  # Initial transparency\n",
    "    # human_fut_positions_st = obs.agent_fut[idx, :, :2].cpu().numpy()\n",
    "    # human_fut_positions = human_fut_positions_st @ obs.agents_from_world_tf[idx, :2, :2].cpu().numpy() + human_pos.reshape(1, 2)\n",
    "    # for future_pos in human_fut_positions:\n",
    "    #     alpha = 0.8*alpha\n",
    "    #     if future_pos[0] < -xLim or future_pos[0] > xLim or future_pos[1] < -yLim or future_pos[1] > yLim or np.isnan(future_pos).any():\n",
    "    #         continue\n",
    "    #     # print(\"Future Pos:\", future_pos)\n",
    "    #     future_circle = plt.Circle(\n",
    "    #         (future_pos[0], future_pos[1]),\n",
    "    #         0.5,\n",
    "    #         facecolor=color,\n",
    "    #         edgecolor=\"k\",\n",
    "    #         lw=0.5,\n",
    "    #         alpha=alpha,\n",
    "    #         zorder=3,\n",
    "    #     )\n",
    "    #     ax.add_artist(future_circle)\n",
    "\n",
    "for coeff in pred_coeffs[ts]:\n",
    "    # Draw the constraint line\n",
    "    a, b, c = coeff\n",
    "    x_vals = np.linspace(-xLim, xLim, 100)\n",
    "    y_vals = (-a * x_vals - c) / b if b != 0 else np.full_like(x_vals, np.nan)  # Handle vertical lines\n",
    "    ax.plot(x_vals, y_vals, color='red', linestyle='--', alpha=0.5, lw=1)\n",
    "\n",
    "robot_color = (1.0, 1.0, 0.0)  # Bright yellow color\n",
    "robot_plot = plt.Circle(\n",
    "            (robot_pos[0], robot_pos[1]),\n",
    "            0.5,\n",
    "            facecolor=robot_color,\n",
    "            edgecolor=\"k\",\n",
    "            lw=0.5,\n",
    "            zorder=3,\n",
    "        )\n",
    "ax.add_artist(robot_plot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588aa39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.613143692499998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = len(dataloader)\n",
    "batch_maxes = np.empty((B,), dtype=float)\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    scene_batch = SceneAgentBatch(batch)\n",
    "    lens = scene_batch.agent_hist_len\n",
    "    batch_idx = torch.arange(lens.size(0), device=lens.device)\n",
    "    time_idx  = lens - 1\n",
    "\n",
    "    pos = scene_batch.agent_hist[batch_idx, time_idx, :2]\n",
    "    pos_np = pos.detach().cpu().numpy()\n",
    "    pos_np = pos_np.reshape(pos_np.shape[0], 1, 2)\n",
    "\n",
    "    tf = scene_batch.world_from_agent_tf\n",
    "\n",
    "    world_pos = transform_coords_np(pos_np, tf)\n",
    "\n",
    "    batch_maxes[i] = np.nanmax(world_pos)\n",
    "\n",
    "global_max = np.nanmax(batch_maxes)\n",
    "global_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312cbbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
