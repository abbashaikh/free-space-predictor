{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781211d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, List, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils import data\n",
    "from trajdata import UnifiedDataset, SceneBatch, AgentBatch\n",
    "from trajdata.data_structures.batch_element import SceneBatchElement\n",
    "from trajdata.data_structures.agent import AgentMetadata, AgentType\n",
    "from trajdata.data_structures.state import StateArray\n",
    "from trajdata.augmentation import NoiseHistories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0728cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_current_states(\n",
    "    batch_elem: SceneBatchElement,\n",
    "    max_agent_num: int\n",
    ") -> np.ndarray:\n",
    "    agents: List[AgentMetadata] = batch_elem.agents\n",
    "    curr_pos = []\n",
    "    for agent in agents:\n",
    "        raw_state: StateArray = batch_elem.cache.get_raw_state(\n",
    "            agent.name, batch_elem.scene_ts\n",
    "        )\n",
    "        state = np.asarray(raw_state)\n",
    "        curr_pos.append(state)\n",
    "    stacked_pos = np.stack(curr_pos, axis=0)\n",
    "    num_agents = stacked_pos.shape[0]\n",
    "    pad_shape = (max_agent_num - num_agents, *stacked_pos.shape[1:])\n",
    "    padding = np.zeros(pad_shape, dtype=stacked_pos.dtype)\n",
    "    return np.concatenate([stacked_pos, padding], axis=0)\n",
    "\n",
    "def get_neighs(\n",
    "    batch_elem: SceneBatchElement,\n",
    "    interaction_radius: float,\n",
    "    max_agent_num: int,\n",
    "):\n",
    "    curr_states = batch_elem.extras[\"curr_states\"]\n",
    "    num_agents = len(curr_states)\n",
    "    is_neigh = []\n",
    "    for state in curr_states:\n",
    "        distances = [\n",
    "            np.linalg.norm(state[:2] - agent_st[:2])\n",
    "            for agent_st in curr_states\n",
    "        ]\n",
    "        is_neigh.append([dist <= interaction_radius for dist in distances])\n",
    "    is_neigh_arr = np.stack(is_neigh, axis=0)\n",
    "    padded = np.zeros((max_agent_num, max_agent_num), dtype=bool)\n",
    "    padded[:num_agents, :num_agents] = is_neigh_arr\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f046949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['eupeds_eth-train-zurich', 'cyprus-eupeds_eth-train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 13797.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Scene Data Index (16 CPUs): 100%|██████████| 1/1 [00:00<00:00, 143.86it/s]\n",
      "Structuring Scene Data Index: 100%|██████████| 1/1 [00:00<00:00, 13066.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Data Samples: 674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log_dir = '../../../data/trained_models/trajectory_prediction'\n",
    "model_dir = os.path.join(log_dir, \"eth-28_May_2025_10_28_45\")\n",
    "\n",
    "with open(os.path.join(model_dir, 'config.json'), 'r', encoding=\"utf-8\") as config_json:\n",
    "    hyperparams = json.load(config_json)\n",
    "# device\n",
    "hyperparams[\"device\"] = \"cpu\"\n",
    "hyperparams[\"trajdata_cache_dir\"] = \"../../../data/pedestrian_datasets/.unified_data_cache\"\n",
    "\n",
    "desired_data=[\n",
    "    \"eupeds_eth-train\",\n",
    "]\n",
    "max_agent_num=20\n",
    "data_dirs = {\n",
    "    \"eupeds_eth\": \"../../../data/pedestrian_datasets/eth_ucy_peds\",\n",
    "}\n",
    "\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "# attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 5.0\n",
    "\n",
    "input_noise = 0.0\n",
    "augmentations = list()\n",
    "if input_noise > 0.0:\n",
    "    augmentations.append(NoiseHistories(stddev=input_noise))\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=desired_data,\n",
    "    centric=\"scene\",\n",
    "    # centric=\"agent\",\n",
    "    max_agent_num=max_agent_num,\n",
    "    history_sec=(0.1, hyperparams[\"history_sec\"]),\n",
    "    future_sec=(0.1, hyperparams[\"prediction_sec\"]),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    augmentations=augmentations if len(augmentations) > 0 else None,\n",
    "    standardize_data=False,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    data_dirs=data_dirs,\n",
    "    verbose=True,\n",
    "    extras={\n",
    "            \"curr_states\": partial(all_current_states, max_agent_num=max_agent_num)\n",
    "            # \"is_neigh\": partial(get_neighs, interaction_radius=5.0),\n",
    "        }\n",
    ")\n",
    "\n",
    "print(f\"# Data Samples: {len(dataset):,}\")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=dataset.get_collate_fn(pad_format=\"right\"),\n",
    "    pin_memory=False if hyperparams[\"device\"] == \"cpu\" else True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    sampler=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52402c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch: SceneBatch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435bc775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'scene_ts', 'dt', 'num_agents', 'agent_type', 'centered_agent_state', 'agent_names', 'agent_hist', 'agent_hist_extent', 'agent_hist_len', 'agent_fut', 'agent_fut_extent', 'agent_fut_len', 'robot_fut', 'robot_fut_len', 'map_names', 'maps', 'maps_resolution', 'vector_maps', 'rasters_from_world_tf', 'centered_agent_from_world_tf', 'centered_world_from_agent_tf', 'scene_ids', 'history_pad_dir', 'extras'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed5ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Agents: tensor([2, 4, 5, 9])\n",
      "Agent History shape: torch.Size([4, 9, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num Agents: {batch.num_agents}\")\n",
    "print(f\"Agent History shape: {batch.agent_hist.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08ba3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [8, 8, 8, 8, 0, 0, 0, 0, 0],\n",
       "        [8, 3, 6, 8, 8, 0, 0, 0, 0],\n",
       "        [8, 8, 8, 7, 7, 7, 7, 8, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.agent_hist_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7cab9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateTensorXYXdYdXddYddSC([ 0.4400,  8.7800,  2.9250, -1.2750,  0.1250,  0.0625,\n",
       "                           -0.3996,  0.9167])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.agent_hist[1,1,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80afa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centered Agent Pos: [3.83 2.78]\n",
      "Centered Agent Sin Cos: [0.3729585  0.92784804]\n"
     ]
    }
   ],
   "source": [
    "centered_agent_state = batch.agent_hist[1,0,0].cpu().detach().numpy()\n",
    "agent_pos = centered_agent_state[:2]\n",
    "agent_sc = centered_agent_state[-2:]\n",
    "print(f\"Centered Agent Pos: {agent_pos}\")\n",
    "print(f\"Centered Agent Sin Cos: {agent_sc}\")\n",
    "\n",
    "cos_agent = agent_sc[-1]\n",
    "sin_agent = agent_sc[-2]\n",
    "centered_world_from_agent_tf: np.ndarray = np.array(\n",
    "    [\n",
    "        [cos_agent, -sin_agent, agent_pos[0]],\n",
    "        [sin_agent, cos_agent, agent_pos[1]],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "centered_agent_from_world_tf: np.ndarray = np.linalg.inv(\n",
    "    centered_world_from_agent_tf\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97679ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "# To Calculate Number of Samples\n",
    "\n",
    "import warnings\n",
    "\n",
    "def bisection(N_low, N_high, sample_function):\n",
    "    \"\"\"\n",
    "    :param N_low: Low guess for the intersection\n",
    "    :param N_high: High guess for the intersection\n",
    "    :param sample_function: Function for which to find the zero crossing\n",
    "    :return: The zero crossing\n",
    "    \"\"\"\n",
    "    # print(f\"Running bisection to find S between {N_low} and {N_high}...\", end=\"\")\n",
    "\n",
    "    a = N_low\n",
    "    b = N_high\n",
    "    f = sample_function\n",
    "\n",
    "    TOL = 1e-9\n",
    "\n",
    "    if a > b:\n",
    "      print('Error: a > b!')\n",
    "      return -1\n",
    "\n",
    "    value_a = f(a)\n",
    "\n",
    "    for i in range(1000):\n",
    "      c = (a + b) / 2.\n",
    "      value_c = f(c)\n",
    "\n",
    "      if value_c == 0 or (b - a) / 2. < TOL:\n",
    "          # print(f\" Found {c:.2f}\")\n",
    "          return c\n",
    "\n",
    "      if np.sign(value_c) == np.sign(value_a):\n",
    "          a = c\n",
    "          value_a = value_c\n",
    "      else:\n",
    "          b = c\n",
    "\n",
    "    print(\"Bisection failed to converge!\")\n",
    "\n",
    "def nchoosek_rooted(n, k, root):\n",
    "    \"\"\"\n",
    "    To avoid numerical errors, an implementation of N choose K where the root is resolved in between\n",
    "    :return: (n choose k)^(1/root)\n",
    "    \"\"\"\n",
    "    y = 1.0\n",
    "    for i in range(k):\n",
    "        y = y * ((n - (k - i - 1.)) / (k - i))**(1. / root)\n",
    "    return y\n",
    "\n",
    "def compute_risk(S, confidence, support):\n",
    "  with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    return 1. - ((confidence / S) ** (1. / (S - support))) * (1. / nchoosek_rooted(S, support, S - support))\n",
    "\n",
    "def find_sample_size(support, risk, confidence):\n",
    "  risk_function = lambda S, support: compute_risk(S, confidence, support)      # Scenario Optimization guarantee for any support\n",
    "  max_risk_function = lambda S: risk - risk_function(S, support)               # \"\" for the specified support limit\n",
    "\n",
    "  S_low = support+1\n",
    "  S_high = 500000\n",
    "\n",
    "  S_double = bisection(S_low, S_high, max_risk_function)\n",
    "  S = np.floor(S_double) + 1\n",
    "\n",
    "  return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d790a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "# To ensure humans do not collide with the robot during initialization\n",
    "# and are within field of view of the robot\n",
    "\n",
    "def is_within_distance(pos1, pos2, distance):\n",
    "    return np.linalg.norm(np.array(pos1) - np.array(pos2)) <= distance\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Calculate the angle between two vectors.\"\"\"\n",
    "    v1_u = v1 / np.linalg.norm(v1)\n",
    "    v2_u = v2 / np.linalg.norm(v2)\n",
    "    angle = np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "    cross = np.cross(np.append(v1_u, 0), np.append(v2_u, 0))\n",
    "    if cross[2] < 0:\n",
    "        angle = -angle\n",
    "    return angle\n",
    "\n",
    "def is_within_fov(robot_pos, robot_orientation, target_pos, fov=90):\n",
    "    \"\"\"Check if target_pos is within the field of view of the robot.\"\"\"\n",
    "    direction_vector = np.array([np.cos(np.deg2rad(robot_orientation)), np.sin(np.deg2rad(robot_orientation))])\n",
    "    target_vector = np.array(target_pos) - np.array(robot_pos)\n",
    "    angle = np.rad2deg(angle_between(direction_vector, target_vector))\n",
    "    return -fov/2 < angle < fov/2\n",
    "\n",
    "# To generate constraint coefficients given human and robot positions\n",
    "def get_constraint_coeff(robot_pos, human_pos, r):\n",
    "    u = human_pos - robot_pos\n",
    "    A = u / np.linalg.norm(u)\n",
    "    a = A[0]\n",
    "    b = A[1]\n",
    "    c = r - A[0]*human_pos[0] - A[1]*human_pos[1]\n",
    "    return np.array([a, b, c]) # Linear inequality: ax + by + c <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae032a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(matrix):\n",
    "    \"\"\"\n",
    "    Checks if the given matrix is symmetric (A == A^T).\n",
    "    Raises a ValueError if it is not symmetric.\n",
    "    \"\"\"\n",
    "    if not np.allclose(matrix, matrix.T):  # Checks if A == A^T (within numerical tolerance)\n",
    "        raise ValueError(\"Matrix is not symmetric!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "635a8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from traj_pred.modules import ModelRegistrar\n",
    "from traj_pred import TrajectoryPredictor\n",
    "\n",
    "# Function to load the trajectron model\n",
    "def load_model(epoch: int):\n",
    "    while epoch > 0:\n",
    "        save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "        if save_path.is_file():\n",
    "            break\n",
    "        epoch -= 1\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, hyperparams[\"device\"])\n",
    "\n",
    "    model = TrajectoryPredictor(\n",
    "        model_registrar=model_registrar,\n",
    "        hyperparams=hyperparams,\n",
    "        log_writer=None,\n",
    "        device=hyperparams[\"device\"])\n",
    "    model.set_environment()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=hyperparams[\"device\"])\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "epoch = 15\n",
    "\n",
    "traj_predictor = load_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Function\n",
    "## To get predictions for a scene\n",
    "## and calculate the constraint coefficients\n",
    "\n",
    "col_radius = 1.0  # Collision radius for agents\n",
    "buffer_dist = 0.5 # Buufer distance considered when choosing robot position\n",
    "vision_radius = 12.0  # Vision radius for robots\n",
    "ph = 12\n",
    "\n",
    "def get_scene_graph_data(batch: SceneBatch, scene_data):\n",
    "    enc = traj_predictor.get_encoding(batch) # TODO\n",
    "    preds = traj_predictor.incremental_forward(\n",
    "        batch=batch,\n",
    "        prediction_horizon=ph,\n",
    "        num_samples=1,\n",
    "        full_dist=True\n",
    "    )\n",
    "\n",
    "    # All humans in the scene\n",
    "    scene_data[\"Human Positions\"] = obs.curr_agent_state[:, :2].cpu().numpy()\n",
    "\n",
    "    # Agent to World frame transformations\n",
    "    agents_to_world_tf = obs.agents_from_world_tf[:, :2, :2].cpu().numpy()\n",
    "    # Append predicted positions of humans to occupied positions\n",
    "    occupied_pos = [pos for pos in scene_data[\"Human Positions\"]]\n",
    "    # Initiate adjaceny matrix\n",
    "    adjacency_matrix = np.zeros((len(obs.agent_name), len(obs.agent_name)), dtype=int)\n",
    "\n",
    "    # Loop through all humans\n",
    "    for idx, human in enumerate(obs.agent_name):\n",
    "        # Append predicted positions to occupied positions (after transformation to world frame)\n",
    "        pred_world_frame = pred[human].reshape(prediction_horizon, 2) @ agents_to_world_tf[idx, :, :] + scene_data[\"Human Positions\"][idx, :]\n",
    "        for jdx in range(prediction_horizon):\n",
    "            occupied_pos.append(pred_world_frame[jdx, :])\n",
    "        # Create adjacency matrix\n",
    "        current_state = scene_data[\"Human Positions\"][idx, :2]\n",
    "        agent_to_world_tf = agents_to_world_tf[idx, :, :]\n",
    "        if obs.num_neigh[idx] > 0:\n",
    "            for neigh_pos in obs.neigh_hist[idx, :obs.num_neigh[idx].item(), -1, :2].cpu().numpy():\n",
    "                neigh_pos = neigh_pos @ agent_to_world_tf + current_state\n",
    "                for jdx, agent_pos in enumerate(obs.curr_agent_state[:, :2].cpu().numpy()):\n",
    "                    if np.linalg.norm(neigh_pos - agent_pos) < 1e-5:\n",
    "                        adjacency_matrix[idx, jdx] = 1\n",
    "        # Store human encodings\n",
    "        scene_data[\"Encodings\"].append(enc[human].cpu().numpy().flatten())\n",
    "\n",
    "    scene_data[\"Adjacency Matrix\"] = adjacency_matrix\n",
    "    check_symmetric(scene_data[\"Adjacency Matrix\"])\n",
    "\n",
    "    # Assign appropriate robot position\n",
    "    # print(\"Occupied positions:\", occupied_pos)\n",
    "    while True: # Generate a random position for the robot\n",
    "        # Ensure the robot's position does not overlap with any occupied positions\n",
    "        robot_position = (random.uniform(-vision_radius, vision_radius), random.uniform(-vision_radius, vision_radius))\n",
    "        if not any(is_within_distance(robot_position, pos, col_radius+buffer_dist) for pos in occupied_pos):\n",
    "            break\n",
    "    scene_data[\"Robot Pose\"] = [robot_position[0], robot_position[1]]\n",
    "\n",
    "    return obs, scene_data\n",
    "\n",
    "\n",
    "def get_constr_data(t, S, obs: AgentBatch, scene_data):\n",
    "\n",
    "    _, preds, _, _ = trajectron.incremental_forward(\n",
    "        timestep=t,\n",
    "        obs=obs,\n",
    "        maps=None,\n",
    "        prediction_horizon=prediction_horizon,\n",
    "        num_samples=int(S),\n",
    "        full_dist=False\n",
    "    )\n",
    "\n",
    "    # Agent to World frame transformations\n",
    "    agents_to_world_tf = obs.agents_from_world_tf[:, :2, :2].cpu().numpy()\n",
    "\n",
    "    constraint_coeffs = []\n",
    "    for idx, human in enumerate(obs.agent_name):\n",
    "        # print(\"Pred shape:\", preds[human].shape)\n",
    "        constraint_pos_st = preds[human][:, :, 0, :].reshape(int(S), 2) # TODO: change the timestpe of prediction positions being considered\n",
    "        constraint_pos = constraint_pos_st @ agents_to_world_tf[idx, :, :] + scene_data[\"Human Positions\"][idx, :]\n",
    "        # print(\"Constraint positions:\", constraint_pos)\n",
    "        for sidx in range(int(S)):\n",
    "            constraint_coeffs.append(get_constraint_coeff(scene_data[\"Robot Pose\"], constraint_pos[sidx, :], col_radius))\n",
    "            # print(\"Constraint Coeffs:\", constraint_coeffs[-1])\n",
    "    scene_data[\"Constraint Coefficients\"] = constraint_coeffs\n",
    "  \n",
    "    return scene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test constraint calculation\n",
    "scene_data: Dict[str, List] = {\n",
    "                \"Robot Pose\": None,\n",
    "                \"Human Positions\": [],\n",
    "                \"Adjacency Matrix\": None,\n",
    "                \"Encodings\": [],\n",
    "                }\n",
    "test_t=287\n",
    "obs, scene_data = get_scene_graph_data(test_t, scene_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_data[\"Constraint Coefficients\"] = None\n",
    "scene_data = get_constr_data(test_t, 10, obs, scene_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
