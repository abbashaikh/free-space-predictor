{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3437dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils import data\n",
    "from trajdata import AgentBatch, AgentType, UnifiedDataset\n",
    "from trajdata.augmentation import NoiseHistories\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa6bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_types = list(product(AgentType, repeat=2))\n",
    "# # edge_types\n",
    "# for edge_type in edge_types:\n",
    "#     print(edge_type[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d093b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_device = \"cpu\"\n",
    "arg_seed = None\n",
    "\n",
    "if not torch.cuda.is_available() or arg_device == 'cpu':\n",
    "    arg_device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.device_count() == 1:\n",
    "        # If you have CUDA_VISIBLE_DEVICES set, which you should,\n",
    "        # then this will prevent leftover flag arguments from\n",
    "        # messing with the device allocation.\n",
    "        arg_device = 'cuda:0'\n",
    "\n",
    "    arg_device = torch.device(arg_device)\n",
    "\n",
    "if arg_device is None:\n",
    "    arg_device = 'cpu'\n",
    "\n",
    "if arg_seed is not None:\n",
    "    random.seed(arg_seed)\n",
    "    np.random.seed(arg_seed)\n",
    "    torch.manual_seed(arg_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(arg_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a99094",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/home/abbas/Projects/trajectron/adaptive-trajectron-plus-plus/experiments/pedestrians/kf_models'\n",
    "model_dir = os.path.join(log_dir, 'eth_1mode_base_tpp-03_Dec_2024_13_01_59')\n",
    "\n",
    "# Load hyperparameters from json\n",
    "conf = 'config.json'\n",
    "config_file = os.path.join(model_dir, conf)\n",
    "if not os.path.exists(config_file):\n",
    "    raise ValueError('Config json not found!')\n",
    "with open(config_file, 'r') as conf_json:\n",
    "    hyperparams = json.load(conf_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb679500",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_data=[\n",
    "    \"eupeds_eth-train\",\n",
    "]\n",
    "data_dirs = {\n",
    "    \"eupeds_eth\": \"~/Projects/trajectron/datasets/eth_ucy_peds\",\n",
    "}\n",
    "\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 5.0\n",
    "\n",
    "input_noise = 0.0\n",
    "augmentations = list()\n",
    "if input_noise > 0.0:\n",
    "    augmentations.append(NoiseHistories(stddev=input_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b91b9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['train-zurich-eupeds_eth', 'train-eupeds_eth-cyprus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Scenes from eupeds_eth: 100%|██████████| 2/2 [00:00<00:00, 2049.00it/s]\n",
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 15592.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Agent Data Index (16 CPUs): 100%|██████████| 1/1 [00:00<00:00, 246.68it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 1/1 [00:00<00:00, 790.48it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=desired_data,\n",
    "    history_sec=(0.1, hyperparams[\"history_sec\"]),\n",
    "    future_sec=(0.1, hyperparams[\"prediction_sec\"]),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    augmentations=augmentations if len(augmentations) > 0 else None,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    data_dirs=data_dirs,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=dataset.get_collate_fn(pad_format=\"right\"),\n",
    "    pin_memory=False if hyperparams[\"device\"] == \"cpu\" else True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    sampler=None,\n",
    ")\n",
    "\n",
    "batch: AgentBatch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.MultiheadAttention( #TODO: update attention module\n",
    "    embed_dim=hp[\"enc_rnn_dim_history\"],\n",
    "    num_heads=1,\n",
    "    kdim=hp[\"enc_rnn_dim_edge\"],\n",
    "    vdim=hp[\"enc_rnn_dim_edge\"],\n",
    "    batch_first=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e0892ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max norm: 4.998409748077393\n",
      "Min norm: 0.4401136338710785\n"
     ]
    }
   ],
   "source": [
    "max_norm = 0.0\n",
    "min_norm = float('inf')\n",
    "for batch in dataloader:\n",
    "    # print(f\"Num Neigh: {batch.neigh_hist.shape[1]}\")\n",
    "    for neigh_idx in range(batch.neigh_hist.shape[1]):\n",
    "        # print(f\"Timestep: {batch.scene_ts.item()}, Neighbour Index: {neigh_idx}\")\n",
    "        neigh_hist = batch.neigh_hist[0, neigh_idx, :, :2]\n",
    "        valid_rows = ~torch.isnan(neigh_hist).all(dim=1)\n",
    "        if valid_rows.any():\n",
    "            filtered_neigh = neigh_hist[valid_rows]\n",
    "            # print(f\"Filtered Neighbour Histories: {filtered_neigh[-1].shape}\")\n",
    "            norm = torch.norm(filtered_neigh[-1])\n",
    "            if norm.item() > max_norm:\n",
    "                max_norm = norm.item()\n",
    "            if norm.item() < min_norm:\n",
    "                min_norm = norm.item()\n",
    "print(f\"Max norm: {max_norm}\")\n",
    "print(f\"Min norm: {min_norm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
