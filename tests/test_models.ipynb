{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f906ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils import data\n",
    "from trajdata import AgentBatch, AgentType, UnifiedDataset\n",
    "from trajdata.augmentation import NoiseHistories\n",
    "\n",
    "from modules.model_registrar import ModelRegistrar\n",
    "from models.trajectory_predictor import TrajectoryPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c001a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/pedestrians.json', 'r', encoding=\"utf-8\") as config_json:\n",
    "    hyperparams = json.load(config_json)\n",
    "hyperparams[\"device\"] = \"cpu\"\n",
    "hyperparams[\"edge_encoding\"] = True\n",
    "hyperparams[\"contrastive_weight\"] = 50.0\n",
    "hyperparams[\"history_sec\"] = 2.8\n",
    "hyperparams[\"prediction_sec\"] = 4.8\n",
    "hyperparams[\"incl_robot_node\"] = False\n",
    "hyperparams[\"map_encoding\"] = False\n",
    "hyperparams[\"preprocess_workers\"] = 16\n",
    "hyperparams[\"trajdata_cache_dir\"] = \"../data/pedestrian_datasets/.unified_data_cache\"\n",
    "\n",
    "hyperparams[\"log_p_yt_xz_max\"] = 6\n",
    "hyperparams[\"single_mode_multi_sample\"] = False\n",
    "hyperparams[\"single_mode_multi_sample_num\"] = 50\n",
    "\n",
    "# hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a7a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_data=[\n",
    "    \"eupeds_eth-train\",\n",
    "]\n",
    "data_dirs = {\n",
    "    \"eupeds_eth\": \"~/Projects/trajectron/datasets/eth_ucy_peds\",\n",
    "}\n",
    "\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 5.0\n",
    "\n",
    "input_noise = 0.0\n",
    "augmentations = list()\n",
    "if input_noise > 0.0:\n",
    "    augmentations.append(NoiseHistories(stddev=input_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda02cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['zurich-eupeds_eth-train', 'eupeds_eth-train-cyprus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 12087.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Agent Data Index (16 CPUs): 100%|██████████| 1/1 [00:00<00:00, 167.14it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 1/1 [00:00<00:00, 1705.00it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=desired_data,\n",
    "    history_sec=(0.1, hyperparams[\"history_sec\"]),\n",
    "    future_sec=(0.1, hyperparams[\"prediction_sec\"]),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    augmentations=augmentations if len(augmentations) > 0 else None,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    data_dirs=data_dirs,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=dataset.get_collate_fn(pad_format=\"right\"),\n",
    "    pin_memory=False if hyperparams[\"device\"] == \"cpu\" else True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    sampler=None,\n",
    ")\n",
    "\n",
    "batch: AgentBatch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f516bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Agent Future Length: {batch.agent_fut_len}\")\n",
    "# print(f\"Neigbors Future Length: {batch.neigh_fut_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd6c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./\"\n",
    "model_registrar = ModelRegistrar(model_dir, hyperparams[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8eaf7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_predictor = TrajectoryPredictor(\n",
    "    model_registrar, hyperparams, log_writer=None, device=hyperparams[\"device\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19514f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_predictor.set_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f450ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_predictor.set_all_annealing_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea83e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['PEDESTRIAN/node_history_encoder', 'PEDESTRIAN/node_future_encoder', 'PEDESTRIAN/edge_influence_encoder', 'UNKNOWN->PEDESTRIAN/edge_encoder', 'VEHICLE->PEDESTRIAN/edge_encoder', 'PEDESTRIAN->PEDESTRIAN/edge_encoder', 'BICYCLE->PEDESTRIAN/edge_encoder', 'MOTORCYCLE->PEDESTRIAN/edge_encoder', 'PEDESTRIAN/p_z_x', 'PEDESTRIAN/q_z_xy', 'PEDESTRIAN/decoder/PreGRU', 'PEDESTRIAN/decoder/GRU', 'PEDESTRIAN/decoder/GMM', 'snce'])\n"
     ]
    }
   ],
   "source": [
    "model_registrar.print_model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58f0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = None\n",
    "step_scheduler = None\n",
    "# TODO: define a different set of optimization parameter if updating pre-trined model\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": model_registrar.get_all_but_name_match(\n",
    "                \"map_encoder\"\n",
    "            ).parameters()\n",
    "        },\n",
    "        {\n",
    "            \"params\": model_registrar.get_name_match(\"map_encoder\").parameters(),\n",
    "            \"lr\": hyperparams[\"map_enc_learning_rate\"],\n",
    "        },\n",
    "    ],\n",
    "    lr=hyperparams[\"learning_rate\"],\n",
    ")\n",
    "# Set Learning Rate\n",
    "if hyperparams[\"learning_rate_style\"] == \"const\":\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "elif hyperparams[\"learning_rate_style\"] == \"exp\":\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer, gamma=hyperparams[\"learning_decay_rate\"]\n",
    "    )\n",
    "\n",
    "if hyperparams[\"lr_step\"] != 0:\n",
    "    step_scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=hyperparams[\"lr_step\"], gamma=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f834218b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'single_mode_multi_sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m trajectory_predictor\u001b[38;5;241m.\u001b[39mstep_all_annealers()\n\u001b[1;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m train_loss, loss_task, loss_nce \u001b[38;5;241m=\u001b[39m \u001b[43mtrajectory_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Task Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_task\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, SNCE Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_nce\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/fsp/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/free_space_predictor/src/models/trajectory_predictor.py:98\u001b[0m, in \u001b[0;36mTrajectoryPredictor.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of the trajectory predictor\"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/free_space_predictor/src/models/trajectory_predictor.py:115\u001b[0m, in \u001b[0;36mTrajectoryPredictor.train_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    113\u001b[0m model: MultimodalGenerativeCVAE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_models_dict[node_type\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    114\u001b[0m agent_type_batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mfor_agent_type(node_type)\n\u001b[0;32m--> 115\u001b[0m enc, loss_mgcvae \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_type_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m losses_mgcvae\u001b[38;5;241m.\u001b[39mappend(loss_mgcvae)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Social NCE loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fsp/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/free_space_predictor/src/modules/mgcvae.py:750\u001b[0m, in \u001b[0;36mMultimodalGenerativeCVAE.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: AgentBatch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    749\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of MG-CVAE\"\"\"\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/free_space_predictor/src/modules/mgcvae.py:780\u001b[0m, in \u001b[0;36mMultimodalGenerativeCVAE.train_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    773\u001b[0m z, kl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(mode, enc, y_e)\n\u001b[1;32m    776\u001b[0m pos_hist: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39magent_hist[\n\u001b[1;32m    777\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(batch\u001b[38;5;241m.\u001b[39magent_hist\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), batch\u001b[38;5;241m.\u001b[39magent_hist_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    778\u001b[0m ]\n\u001b[0;32m--> 780\u001b[0m log_p_y_xz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_nr_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_hist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m log_p_y_xz_mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(log_p_y_xz, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [nbs]\u001b[39;00m\n\u001b[1;32m    793\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(log_p_y_xz_mean)\n",
      "File \u001b[0;32m~/Projects/free_space_predictor/src/modules/mgcvae.py:714\u001b[0m, in \u001b[0;36mMultimodalGenerativeCVAE.decoder\u001b[0;34m(self, mode, enc, x_nr_t, y, y_r, pos_hist, z, dt, num_samples)\u001b[0m\n\u001b[1;32m    700\u001b[0m num_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    701\u001b[0m y_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_y_xz(\n\u001b[1;32m    702\u001b[0m     mode,\n\u001b[1;32m    703\u001b[0m     enc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m     num_components\u001b[38;5;241m=\u001b[39mnum_components,\n\u001b[1;32m    712\u001b[0m )\n\u001b[0;32m--> 714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msingle_mode_multi_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    715\u001b[0m     log_p_ynt_xz \u001b[38;5;241m=\u001b[39m y_dist\u001b[38;5;241m.\u001b[39mlog_prob(torch\u001b[38;5;241m.\u001b[39mnan_to_num(y))\n\u001b[1;32m    716\u001b[0m     log_p_yt_xz \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlogsumexp(log_p_ynt_xz, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    717\u001b[0m         log_p_ynt_xz\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    718\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'single_mode_multi_sample'"
     ]
    }
   ],
   "source": [
    "trajectory_predictor.curr_iter = 0\n",
    "trajectory_predictor.step_all_annealers()\n",
    "\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "train_loss, loss_task, loss_nce = trajectory_predictor(batch)\n",
    "print(\n",
    "    f\"Total Loss: {train_loss.detach().item():.4f}, Task Loss: {loss_task.item():.4f}, SNCE Loss: {loss_nce.item():.4f}\"\n",
    ")\n",
    "train_loss.backward()\n",
    "\n",
    "# Clipping gradients.\n",
    "if hyperparams[\"grad_clip\"] is not None:\n",
    "    nn.utils.clip_grad_value_(\n",
    "        model_registrar.parameters(), hyperparams[\"grad_clip\"]\n",
    "    )\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "# Stepping forward the learning rate scheduler and annealers.\n",
    "lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e26aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
